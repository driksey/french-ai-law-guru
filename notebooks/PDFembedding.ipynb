{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2cdd43-9441-428a-b6a9-dffc16199fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r /work/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ebeafe2-0bdb-4df4-8376-619cf5cb77bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faq_chatbot.utils import load_faqs\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc2a645-4456-4049-a872-2a449684359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdfs(path=str):\n",
    "    pdfs = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path  = os.path.join(path, filename)\n",
    "            loader = PyPDFLoader(file_path )\n",
    "            pdfs.extend(loader.load())\n",
    "    return pdfs\n",
    "\n",
    "path = \"/work/docs\"\n",
    "docs = load_pdfs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81511acb-5cd9-45ec-983a-3b2b89d4317d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='REGUL A TION (EU) 2024/1689 OF THE EUR OPEAN P ARLIAMENT AND OF THE CO UNCIL\n",
      "of 13 June 2024\n",
      "laying do wn har monised r ules on ar tif icial intelligence and amending Regulations (EC) No 300/2008, \n",
      "(EU) No 167/2013, (EU) No 168/2013, (EU) 2018/858, (EU) 2018/1139 and (EU) 2019/2144 and \n",
      "Directiv es 2014/90/EU, (EU) 2016/797 and (EU) 2020/1828 (Ar tif icial Intelligence A ct)\n",
      "(T ext with EEA relevance)\n",
      "THE EUR OPEAN P ARLIAMENT AND THE COUNCIL OF THE EUR OPEAN UNION,\n",
      "Having regard to the T reaty on the Functioning of the European Union, and in par ticular Ar ticles 16 and 114 thereof,\n",
      "Having regard to the proposal from the European Commission,\n",
      "Af ter transmission of the draf t legislative act to the national parliaments,\n",
      "Having regard to the opinion of the European Economic and Social Committe e (\n",
      "1\n",
      "),\n",
      "Having regard to the opinion of the European Central Bank (\n",
      "2\n",
      "),\n",
      "Having regard to the opinion of the Committee of the Regions (\n",
      "3\n",
      "),' metadata={'producer': 'PDFlib+PDI 9.0.7p3 (C++/Win64)', 'creator': 'Servigistics Arbortext Publishing Engine', 'creationdate': '2024-07-11T14:47:17+02:00', 'author': 'Publications Office of the European Union L-2985 Luxembourg LUXEMBOURG', 'keywords': 'ISSN 1977-0677', 'moddate': '2024-07-11T15:55:28+02:00', 'subject': 'I Legislative acts', 'title': 'Regulation (EU) 2024/1689 of the European Parliament and of the Council of 13 June 2024 laying down harmonised rules on artificial intelligence and amending Regulations (EC) No 300/2008, (EU) No 167/2013, (EU) No 168/2013, (EU) 2018/858, (EU) 2018/1139 and (EU) 2019/2144 and Directives 2014/90/EU, (EU) 2016/797 and (EU) 2020/1828 (Artificial Intelligence Act)Text with EEA relevance.', 'source': '/work/docs/AI ACT.pdf', 'total_pages': 144, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "print(split_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48d65ece-767e-4224-ab52-4459ca2e6825",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in split_docs:\n",
    "    category = doc.metadata[\"source\"].split(\"/\")[-2]\n",
    "    doc.metadata = {\n",
    "        \"source\": doc.metadata[\"source\"],\n",
    "        \"category\": category\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc99225d-d8b0-46f1-b0b7-ec5ff920b5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/work/docs/AI ACT.pdf', 'category': 'docs'}, page_content='REGUL A TION (EU) 2024/1689 OF THE EUR OPEAN P ARLIAMENT AND OF THE CO UNCIL\\nof 13 June 2024\\nlaying do wn har monised r ules on ar tif icial intelligence and amending Regulations (EC) No 300/2008, \\n(EU) No 167/2013, (EU) No 168/2013, (EU) 2018/858, (EU) 2018/1139 and (EU) 2019/2144 and \\nDirectiv es 2014/90/EU, (EU) 2016/797 and (EU) 2020/1828 (Ar tif icial Intelligence A ct)\\n(T ext with EEA relevance)\\nTHE EUR OPEAN P ARLIAMENT AND THE COUNCIL OF THE EUR OPEAN UNION,\\nHaving regard to the T reaty on the Functioning of the European Union, and in par ticular Ar ticles 16 and 114 thereof,\\nHaving regard to the proposal from the European Commission,\\nAf ter transmission of the draf t legislative act to the national parliaments,\\nHaving regard to the opinion of the European Economic and Social Committe e (\\n1\\n),\\nHaving regard to the opinion of the European Central Bank (\\n2\\n),\\nHaving regard to the opinion of the Committee of the Regions (\\n3\\n),')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b39b16fe-32bd-4e54-88c3-17100901280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "def store_docs_with_embeddings(docs):\n",
    "    model = HuggingFaceEmbeddings(\n",
    "        model_name=EMB_MODEL,\n",
    "        model_kwargs={\"device\": \"cpu\"}  \n",
    "    )\n",
    "    vectorstore = Chroma.from_documents(docs, embedding=model, collection_name =f\"docs_{random.random()}\")\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "407b0a9d-dd9e-41b4-920a-33c2f31172e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import chromadb\n",
    "import random\n",
    "\n",
    "vectorstore = store_docs_with_embeddings(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25d5420f-120d-4d1d-a032-b2cbea9f1ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5c166eb-4a18-491d-b76b-904202cead04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/work/docs/GDPR.pdf', 'category': 'docs'}, page_content=\"personal data of the data subject's request. \\n(67)  Methods by whic h to restr ict the processing of personal data could include, inter alia, te mporar ily mo ving the \\nselect ed data to another processing system, making the selecte d personal data unavai lable to users, or te mporar ily \\nremo ving published data from a website . In autom ated fi ling syste ms, the restr iction of processing should in \\npr inciple be ensured by tec hnical means in such a manner that the personal data are not subject to fur ther \\nprocessing operations and cannot be chang ed. The fa ct that the processing of personal data is restr icted should \\nbe clearly indicated in the system. \\n(68)  T o fur ther strengthen the control o ver his or her o wn data, where the processing of personal data is car r ied out \\nby automat ed means, the data subject should also be allo wed to receive personal data concer ning him or her\"),\n",
       " Document(metadata={'source': '/work/docs/AI ACT.pdf', 'category': 'docs'}, page_content='(32) ‘te sting data’ means data used f or providing an independent evaluation of the AI system in order t o conf ir m the \\nexpect ed perform ance of that syste m bef ore its placing on the market or putting into ser vice;\\n(33) ‘in put data’ means data provided to or directly acquired by an AI syste m on the basis of which the syste m produces an \\noutput ;\\n(34) ‘biometr ic data’ means personal data resulting from specific te chnical processing relating t o the physical , physiolo gical \\nor behavi oural ch aracter istics of a natural person, such as facial images or dactyloscopic data;\\n(35) ‘biometr ic identifica tion’ means the automat ed recognition of physical, physiolo gical, behavioural, or psy chological \\nhuman features f or the pur pose of establishing the identity of a natural person b y comp ar ing biometr ic data of that \\nindividual to biometr ic data of individuals st ored in a database;'),\n",
       " Document(metadata={'category': 'docs', 'source': '/work/docs/AI ACT.pdf'}, page_content='pro viding or suppor ting the access to data ma y also suppor t the pro vision of high-quality data f or the training, \\nvalidation and testing of AI syste ms.\\n(69) The r ight to pr ivacy and to protection of personal data must be guarante ed throughout the entire lif ecy cle of the AI \\nsyste m. In this regard , the pr inciples of data minimisation and data protection b y design and by default, as set out in \\nUni on data protect ion law , are applicable when personal data are processed. Measures take n by provid ers to ensure \\ncom pliance with those pr inciples ma y include not only anonymisati on and encr ypt ion, but also the use of \\nt echnology that per mits algor ithms to be brought to the data and allows training of AI systems without the \\ntransmission between par ties or cop ying of the raw or str uctured data themselves, without prejudice to the \\nrequirements on data gover nance provid ed f or in this Regulation.'),\n",
       " Document(metadata={'category': 'docs', 'source': '/work/docs/AI ACT.pdf'}, page_content='recommendations, or decisions, which can inf luence physica l and vir tual envir onments, and to a capability of AI \\nsyste ms to der ive models or algor ithms, or both, from in puts or data. The tec hniques that enable inf erence while \\nbuilding an AI syste m include machi ne lear ning approaches that lear n from data how t o ac hieve cer tain objectives, \\nand logic- and kno wledge-based approac hes that inf er from encoded knowle dge or symbolic representation of the \\ntask to be solved. The capacity of an AI syste m to infer transcends basic data processing by enabling lear ning, \\nreasoning or modelling. The ter m ‘mach ine-based’ refe rs to the f act that AI systems r un on machi nes. The reference \\nt o explicit or im plicit objectives underscores that AI syste ms can operat e according to explicit def ined objectives or \\nt o imp licit objectives. The objectives of the AI system ma y be diff erent from the inte nded pur pose of the AI system'),\n",
       " Document(metadata={'category': 'docs', 'source': '/work/docs/GDPR.pdf'}, page_content='fundamental r ights and freedoms of the data subject are not o ver r iding, taking into consideration the reasonable \\nexpectations of data subjects based on their relationship with the controller . Such legitimate interest could exist \\nf or example where there is a relevant and appropr iat e relationship between the data subject and the controller in \\nsituations such as where the data subject is a client or in the ser vice of the controller . A t any rate the existen ce of \\na legitimate inte rest would need careful assessment including whether a data subject can reasonably expect at the \\ntime and in the cont ext of the collection of the personal data that processing f or that pur pose ma y take place. \\nThe inter ests and fundamental r ights of the data subject could in par ticular o ver r ide the inter est of the data \\ncontroller where personal data are processed in circumstances where data subjects do not reasonably expect')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Can we use personnal data with AI?\"\n",
    "docs = retriever.invoke(query)\n",
    "docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f47ff6c2-5a0f-40b6-a775-c2698255e018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': <__main__.test object at 0x70d50eb5cb50>, 'b': <__main__.test object at 0x70d50ee37050>, 'c': <__main__.test object at 0x70d50ee354d0>}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class test:\n",
    "    def __init__(self):\n",
    "        test.name=''\n",
    "\n",
    "example1 = test()\n",
    "example1.name = \"a\"\n",
    "example2 = test()\n",
    "example2.name = \"b\"\n",
    "example3 = test()\n",
    "example3.name = \"c\"\n",
    "\n",
    "tools = [example1, example2, example3]\n",
    "\n",
    "\n",
    "# print(example1.name)\n",
    "\n",
    "result = {tool.name: tool for tool in tools}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb257326-5ff4-45f1-a45b-afc534602568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA dispo ? False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA dispo ?\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39164a9a-0a38-4fea-97df-61c83a78b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "def create_rag_tool(retriever):\n",
    "    \"\"\"Create a RAG tool for document retrieval.\"\"\"\n",
    "    return Tool(\n",
    "        name=\"tool_rag\",\n",
    "        description=\"\"\"Tool to retrieve the k closest documents answering a question on IA regulation.\"\"\",\n",
    "        func=lambda query: retrieve_documents(query, retriever)\n",
    "    )\n",
    "tool_rag = create_rag_tool(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27a61b99-1236-4638-ae2b-268d1332c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "\n",
    "# Charger le .env depuis la racine\n",
    "ROOT = Path(\"/work\")\n",
    "load_dotenv(ROOT / \".env\")\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "HF_MODEL = os.getenv(\"HF_MODEL\", \"google/gemma-2-2b-it\")\n",
    "\n",
    "if not HF_TOKEN:\n",
    "    raise EnvironmentError(\"Set HF_TOKEN in environment (see .env.example)\")\n",
    "\n",
    "\n",
    "def create_huggingface_client():\n",
    "    \"\"\"Create and return a HuggingFace chat model client.\"\"\"\n",
    "    # Initialize LangChain HuggingFace client\n",
    "    llm = HuggingFaceEndpoint(\n",
    "        repo_id=HF_MODEL,\n",
    "        huggingfacehub_api_token=HF_TOKEN,\n",
    "        temperature=0.7,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "    )\n",
    "\n",
    "    # Initialize chat model for better conversation handling\n",
    "    chat_model = ChatHuggingFace(\n",
    "        llm=llm,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return chat_model\n",
    "    \n",
    "chat_model = create_huggingface_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d60dd1a-916f-4067-964d-de7b00468d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import START, END, MessagesState, StateGraph\n",
    "from langchain_huggingface import ChatHuggingFace\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"Node for executing tools in the agent workflow.\"\"\"\n",
    "    \n",
    "    def __init__(self, tools: list) -> None:\n",
    "        # Outils disponibles\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        # Récupère le dernier message de la liste \"messages\" dans les entrées\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            # Exécute l'outil spécifié et retourne le résultat\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=str(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "def create_prompt():\n",
    "    \"\"\"Create the system prompt for the agent.\"\"\"\n",
    "    return ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant answering user questions using only the provided context. \"\n",
    "                   \"Answer the question directly if no context is needed. \"\n",
    "                   \"If necessary, call the RAG tool to perform an initial search for relevant information. \"\n",
    "                   \"When you no longer call a tool, your last response will be considered the final answer.\"),\n",
    "        (\"placeholder\", \"{history}\"),\n",
    "    ])\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState, chat_model, tools):\n",
    "    \"\"\"Call the model with tools bound.\"\"\"\n",
    "    prompt = create_prompt()\n",
    "    chat_model_with_tools = chat_model.bind_tools(tools)\n",
    "    chat_model_with_prompt = prompt | chat_model_with_tools\n",
    "    response = chat_model_with_prompt.invoke({\"history\": state[\"messages\"]})\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "def route_tools(state: MessagesState):\n",
    "    \"\"\"Route to tools if tool calls are present, otherwise end.\"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and ai_message.tool_calls and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "def define_graph(chat_model, tools):\n",
    "    \"\"\"Define the agent workflow graph.\"\"\"\n",
    "    workflow = StateGraph(MessagesState)\n",
    "    \n",
    "    # Créer une fonction partielle pour call_model avec les outils\n",
    "    def call_model_with_tools(state):\n",
    "        return call_model(state, chat_model, tools)\n",
    "    \n",
    "    workflow.add_node(\"model\", call_model_with_tools)\n",
    "\n",
    "    tool_node = BasicToolNode(tools=tools)\n",
    "    workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        \"model\",\n",
    "        route_tools,\n",
    "        {\"tools\": \"tools\", END: END},\n",
    "    )\n",
    "\n",
    "    workflow.add_edge(START, \"model\")\n",
    "    workflow.add_edge(\"tools\", \"model\")\n",
    "\n",
    "    agent = workflow.compile()\n",
    "    return agent\n",
    "    \n",
    "agent = define_graph(chat_model, [tool_rag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6092afb-d142-45b7-8dda-89ba10ffb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is it legal to use real resumes for chatbot training?\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n",
    "response = agent.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fa2e4c6-0617-4163-be80-348dc6a00dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Response: The legality of using real resumes for chatbot training ultimately depends on the source of the resumes and the intended use of the chatbot's output. If the resumes were obtained legally and the intended use of the chatbot's output is for internal personnel recruitment and hiring purposes, it is generally acceptable. However, if the resumes were obtained without consent or were gathered from external sources for other purposes, it may violate privacy rights and potentially be considered a breach of GDPR (General Data Protection Regulation) in the European Union or other privacy laws, depending on the specifics of the use case. It is best practice to obtain consent from individuals for any sensitive information used in training AI or to modify such information for anonymization or aggregation to mitigate privacy concerns. When in doubt, seeking legal counsel is advised to ensure compliance with privacy laws.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92cd14d4-cb37-4bb8-8aae-153d665c60e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke({\"messages\": question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7996040-b921-4340-8c24-598df3f12dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Yes, it is legal to use real resumes for chatbot training purposes as long as you have obtained explicit consent from the individuals whose resumes you are using. However, there are certain data protection laws that must be followed, and you should ensure that the information is used in compliance with privacy policies and agreements with the individuals and any regulatory requirements in your specific industry and country. You should also consider any confidentiality obligations and any other legal requirements, such as GDPR or HIPAA for healthcare organizations. It's crucial to protect the sensitive information and anonymize the resumes where necessary to ensure compliance and protect privacy. The resumes can be used for training natural language processing (NLP) models for chatbots or for generating human-like responses in recruiting-related tasks such as interview scheduling, job matching, or candidate screening. Real resumes are beneficial because they provide a realistic and diverse set of data for the chatbot to learn from and improve its accuracy and performance. It's recommended to only use resumes from the industry or company you are designing the chatbot for, as this will improve its accuracy in understanding the specific terminology and jargon used in that area. Overall, it is permissible to use real resumes as long as you maintain privacy and follow legal and ethical guidelines in handling sensitive data.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a96d4-be7d-401f-8f18-82388384c595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
